{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Exercises\n",
    "In this exercise, we'll continue working with the titanic dataset and building logistic regression models. Throughout this exercise, be sure you are training, evaluation, and comparing models on the train and validate datasets. The test dataset should only be used for your final model.\n",
    "\n",
    "For all of the models you create, choose a threshold that optimizes for accuracy.\n",
    "\n",
    "Do your work for these exercises in either a notebook or a python script named model within your classification-exercises repository. Add, commit, and push your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports ready\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import acquire\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "print(\"Imports ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class  embark_town  alone  Q  S  \n",
       "0        S  Third  Southampton      0  0  1  \n",
       "1        C  First    Cherbourg      0  0  0  \n",
       "2        S  Third  Southampton      1  0  1  \n",
       "3        S  First  Southampton      0  0  1  \n",
       "4        S  Third  Southampton      1  0  1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing and cleaning up data\n",
    "titanic = acquire.get_titanic_data()\n",
    "\n",
    "#fills age null with mode age, creates dummies, and drops unneeded columns\n",
    "titanic = acquire.prep_titanic(titanic)\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "passenger_id    0\n",
       "survived        0\n",
       "pclass          0\n",
       "sex             0\n",
       "age             0\n",
       "sibsp           0\n",
       "parch           0\n",
       "fare            0\n",
       "embarked        0\n",
       "class           0\n",
       "embark_town     0\n",
       "alone           0\n",
       "Q               0\n",
       "S               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking nulls\n",
    "titanic.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  (497, 2) , validate:  (214, 2) , test:  (178, 2)\n",
      "train:  (497, 1) , validate:  (214, 1) , test:  (178, 1)\n"
     ]
    }
   ],
   "source": [
    "# prep from curriculum\n",
    "X1 = titanic[['pclass','fare']]\n",
    "y1 = titanic[['survived']]\n",
    "\n",
    "X1_train_validate, X1_test, y1_train_validate, y1_test = train_test_split(X1, y1, test_size = .20, random_state = 123)\n",
    "\n",
    "X1_train, X1_validate, y1_train, y1_validate = train_test_split(X1_train_validate, y1_train_validate, test_size = .30, random_state = 123)\n",
    "\n",
    "print(\"train: \", X1_train.shape, \", validate: \", X1_validate.shape, \", test: \", X1_test.shape)\n",
    "print(\"train: \", y1_train.shape, \", validate: \", y1_validate.shape, \", test: \", y1_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    313\n",
       "1    184\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# More zeros, which means most did not survive\n",
    "y1_train.survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual  baseline\n",
       "689       1         0\n",
       "191       0         0\n",
       "634       0         0\n",
       "623       0         0\n",
       "244       0         0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our baseline model will be that every passenger does not survive\n",
    "models = pd.DataFrame(y1_train)\n",
    "models['baseline'] = 0\n",
    "\n",
    "models.columns = ['actual','baseline']\n",
    "models.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>actual</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "actual      0    1\n",
       "baseline          \n",
       "0         313  184"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross tab of our baseline versus actual\n",
    "pd.crosstab(models['baseline'], models['actual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The baseline model is 62.98 percent.\n"
     ]
    }
   ],
   "source": [
    "# let's calculate the accuracy\n",
    "# positive will be not survived\n",
    "# (TP + TN) / (TP + TN + FP + FN)\n",
    "true_p = 313\n",
    "false_p = 184\n",
    "true_n = 0\n",
    "false_n = 0\n",
    "\n",
    "base_acc = (true_p + true_n) / (true_p + true_n + false_p + false_n)\n",
    "base_acc\n",
    "print(\"The baseline model is\",round(base_acc * 100, 2),\"percent.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc05e096c10>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(titanic.age, titanic.pclass, hue=titanic.survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create another model that includes age in addition to fare and pclass. Does this model perform better than your previous one (the baseline model)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps\n",
    "- Create Basic Model\n",
    "\n",
    "    1. Create model object\n",
    "\n",
    "    2. Fit the model to the data\n",
    "\n",
    "    3. Predict labels\n",
    "\n",
    "    4. Estimate probability of a label estimate\n",
    "\n",
    "- Evaluate Model\n",
    "\n",
    "    1. Accuracy\n",
    "\n",
    "    2. Classification report\n",
    "\n",
    "    3. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  (497, 3) , validate:  (214, 3) , test:  (178, 3)\n",
      "train:  (497, 1) , validate:  (214, 1) , test:  (178, 1)\n"
     ]
    }
   ],
   "source": [
    "X2 = titanic[['pclass','fare','age']]\n",
    "y2 = titanic[['survived']]\n",
    "\n",
    "X2_train_validate, X2_test, y2_train_validate, y2_test = train_test_split(X2, y2, test_size = .20, random_state = 123)\n",
    "\n",
    "X2_train, X2_validate, y2_train, y2_validate = train_test_split(X2_train_validate, y2_train_validate, test_size = .30, random_state = 123)\n",
    "\n",
    "print(\"train: \", X2_train.shape, \", validate: \", X2_validate.shape, \", test: \", X2_test.shape)\n",
    "print(\"train: \", y2_train.shape, \", validate: \", y2_validate.shape, \", test: \", y2_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Basic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Logistic Regression Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "logit = LogisticRegression(C=1, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Model to the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X2_train, y2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the coefficients and intercept of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-0.97715693  0.00434782 -0.03720437]]\n",
      "Intercept: \n",
      " [2.59154884]\n"
     ]
    }
   ],
   "source": [
    "print('Coefficient: \\n', logit.coef_)\n",
    "print('Intercept: \\n', logit.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate whether or not a passenger would survive, using the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_pred = logit.predict(X2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate the probability of a passenger surviving, using the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_pred_proba = logit.predict_proba(X2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model on Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.72\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'.format(logit.score(X2_train, y2_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Model 1\n",
      " [[278  35]\n",
      " [103  81]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix for Model 1\\n\",confusion_matrix(y2_train, y2_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Precision, Recall, F1-score, and Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.89      0.80       313\n",
      "           1       0.70      0.44      0.54       184\n",
      "\n",
      "    accuracy                           0.72       497\n",
      "   macro avg       0.71      0.66      0.67       497\n",
      "weighted avg       0.72      0.72      0.70       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y2_train, y2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of model 2 is 72.23 percent.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model2_acc = accuracy_score(y2_train, y2_pred)\n",
    "print('The accuracy of model 2 is',round(model2_acc * 100, 2), 'percent.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Include sex in your model as well. Note that you'll need to encode or create a dummy variable of this feature before including it in a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding the sex feature, and adjusting the weights of c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class  embark_town  alone  Q  S  male  \n",
       "0        S  Third  Southampton      0  0  1     1  \n",
       "1        C  First    Cherbourg      0  0  0     0  \n",
       "2        S  Third  Southampton      1  0  1     0  \n",
       "3        S  First  Southampton      0  0  1     0  \n",
       "4        S  Third  Southampton      1  0  1     1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dummy variables for sex\n",
    "df_dummies = pd.get_dummies(titanic['sex'],drop_first=True)\n",
    "    \n",
    "#add dummy variables to original df\n",
    "titanic = pd.concat([titanic, df_dummies], axis=1)\n",
    "\n",
    "#check to see it was added correctly\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  (497, 4) , validate:  (214, 4) , test:  (178, 4)\n",
      "train:  (497, 1) , validate:  (214, 1) , test:  (178, 1)\n"
     ]
    }
   ],
   "source": [
    "X3 = titanic[['pclass','fare','age','male']]\n",
    "y3 = titanic[['survived']]\n",
    "\n",
    "X3_train_validate, X3_test, y3_train_validate, y3_test = train_test_split(X3, y3, test_size = .20, random_state = 123)\n",
    "\n",
    "X3_train, X3_validate, y3_train, y3_validate = train_test_split(X3_train_validate, y3_train_validate, test_size = .30, random_state = 123)\n",
    "\n",
    "print(\"train: \", X3_train.shape, \", validate: \", X3_validate.shape, \", test: \", X3_test.shape)\n",
    "print(\"train: \", y3_train.shape, \", validate: \", y3_validate.shape, \", test: \", y3_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Logistic Regression Object\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "logit3 = LogisticRegression(C=1, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit Model to the Data\n",
    "logit3.fit(X3_train, y3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-1.08363353e+00  1.73245998e-03 -3.16663020e-02 -2.16797714e+00]]\n",
      "Intercept: \n",
      " [4.0654252]\n"
     ]
    }
   ],
   "source": [
    "# Print the coefficients and intercept of the model\n",
    "print('Coefficient: \\n', logit3.coef_)\n",
    "print('Intercept: \\n', logit3.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate whether or not a passenger would survive, using the training data\n",
    "y3_pred = logit3.predict(X3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the probability of a passenger surviving, using the training data\n",
    "y3_pred_proba = logit3.predict_proba(X3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.77\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Model on Train\n",
    "# Compute the accuracy\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'.format(logit.score(X3_train, y3_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of model 3 is 77.26 percent.\n"
     ]
    }
   ],
   "source": [
    "model3_acc = accuracy_score(y3_train, y3_pred)\n",
    "print('The accuracy of model 3 is',round(model3_acc * 100, 2), 'percent.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes\n",
    "- Model 1 c=1\n",
    "- Model 2 c=.01 and sex added\n",
    "- Accuracy of Model 1 and 2 are the same at .37\n",
    "- The baseline model is still more accurate than both these models at .67"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Try out other combinations of features and models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Will try using features that make the most sense - the person being a child, female, and rich making them most likely to survive\n",
    "    - age < 13\n",
    "    - pclass == 1\n",
    "    - sex == 0 (female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "      <th>male</th>\n",
       "      <th>is_child</th>\n",
       "      <th>is_first_class</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class  embark_town  alone  Q  S  male  is_child  is_first_class  \\\n",
       "0        S  Third  Southampton      0  0  1     1     False           False   \n",
       "1        C  First    Cherbourg      0  0  0     0     False            True   \n",
       "2        S  Third  Southampton      1  0  1     0     False           False   \n",
       "3        S  First  Southampton      0  0  1     0     False            True   \n",
       "4        S  Third  Southampton      1  0  1     1     False           False   \n",
       "\n",
       "   male  \n",
       "0     1  \n",
       "1     0  \n",
       "2     0  \n",
       "3     0  \n",
       "4     1  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding columns to the titanic df, then will split into train,test,validate\n",
    "train_titanic = titanic\n",
    "train_titanic['is_child'] = (train_titanic.age < 12)\n",
    "train_titanic['is_first_class'] = (train_titanic.pclass == 1)\n",
    "\n",
    "#create dummy variables for sex column\n",
    "df_dummies = pd.get_dummies(train_titanic['sex'],drop_first=1)\n",
    "    \n",
    "#add dummy variables to original df\n",
    "train_titanic = pd.concat([train_titanic, df_dummies], axis=1)\n",
    "\n",
    "train_titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>alone</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "      <th>male</th>\n",
       "      <th>is_child</th>\n",
       "      <th>is_first_class</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  sibsp  parch     fare embarked  class  alone  Q  S  male  \\\n",
       "0         0      1      0   7.2500        S  Third      0  0  1     1   \n",
       "1         1      1      0  71.2833        C  First      0  0  0     0   \n",
       "2         1      0      0   7.9250        S  Third      1  0  1     0   \n",
       "3         1      1      0  53.1000        S  First      0  0  1     0   \n",
       "4         0      0      0   8.0500        S  Third      1  0  1     1   \n",
       "\n",
       "   is_child  is_first_class  male  \n",
       "0     False           False     1  \n",
       "1     False            True     0  \n",
       "2     False           False     0  \n",
       "3     False            True     0  \n",
       "4     False           False     1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropping columns we don't need\n",
    "train_titanic = train_titanic.drop(['passenger_id','pclass','sex','age','embark_town'],axis=1)\n",
    "train_titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  (497, 4) , validate:  (214, 4) , test:  (178, 4)\n",
      "train:  (497, 1) , validate:  (214, 1) , test:  (178, 1)\n"
     ]
    }
   ],
   "source": [
    "# choosing features and splitting into train, validate, test\n",
    "# first, let's just test survival by female, child, and first_class\n",
    "X4 = train_titanic[['is_child','male','is_first_class']]\n",
    "y4 = train_titanic[['survived']]\n",
    "\n",
    "X4_train_validate, X4_test, y4_train_validate, y4_test = train_test_split(X4, y4, test_size = .20, random_state = 123)\n",
    "\n",
    "X4_train, X4_validate, y4_train, y4_validate = train_test_split(X4_train_validate, y4_train_validate, test_size = .30, random_state = 123)\n",
    "\n",
    "print(\"train: \", X4_train.shape, \", validate: \", X4_validate.shape, \", test: \", X4_test.shape)\n",
    "print(\"train: \", y4_train.shape, \", validate: \", y4_validate.shape, \", test: \", y4_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Basic Model\n",
    "# Create Logistic Regression Object\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "logit4 = LogisticRegression(C=1, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit Model to the Data\n",
    "logit4.fit(X4_train, y4_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[ 0.81407221 -1.11579946 -1.11579946  1.5282524 ]]\n",
      "Intercept: \n",
      " [0.36144037]\n"
     ]
    }
   ],
   "source": [
    "#Print the coefficients and intercept of the model\n",
    "print('Coefficient: \\n', logit4.coef_)\n",
    "print('Intercept: \\n', logit4.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate whether or not a passenger would survive, using the training data\n",
    "y4_pred = logit4.predict(X4_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the probability of a passenger surviving, using the training data\n",
    "y_pred_proba = logit4.predict_proba(X4_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.77\n"
     ]
    }
   ],
   "source": [
    "#Evaluate Model on Train\n",
    "#Compute the accuracy\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'.format(logit4.score(X4_train, y4_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Model 1\n",
      " [[260  53]\n",
      " [ 62 122]]\n"
     ]
    }
   ],
   "source": [
    "#Accuracy of Logistic Regression classifier on training set: 0.37\n",
    "#Create a confusion matrix\n",
    "print(\"Confusion Matrix for Model 1\\n\",confusion_matrix(y4_train, y4_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82       313\n",
      "           1       0.70      0.66      0.68       184\n",
      "\n",
      "    accuracy                           0.77       497\n",
      "   macro avg       0.75      0.75      0.75       497\n",
      "weighted avg       0.77      0.77      0.77       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Compute Precision, Recall, F1-score, and Support\n",
    "print(classification_report(y4_train, y4_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of model 3 is 76.86 percent.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "model4_acc = accuracy_score(y4_train, y4_pred)\n",
    "\n",
    "print('The accuracy of model 3 is',round(model4_acc * 100, 2), 'percent.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Changing c from 1 to .01 decreased accuracy\n",
    "- Increasing c to 10, 100 has no effect on accuracy\n",
    "- Changing features specifically to first class, female, children did not increase accuracy\n",
    "- will try to only account for children"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try the same features but without is_child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  (497, 3) , validate:  (214, 3) , test:  (178, 3)\n",
      "train:  (497, 1) , validate:  (214, 1) , test:  (178, 1)\n"
     ]
    }
   ],
   "source": [
    "# choosing features and splitting into train, validate, test\n",
    "# first, let's just test survival by female, child, and first_class\n",
    "X5 = train_titanic[['male','is_first_class']]\n",
    "y5 = train_titanic[['survived']]\n",
    "\n",
    "X5_train_validate, X5_test, y5_train_validate, y5_test = train_test_split(X5, y5, test_size = .20, random_state = 123)\n",
    "\n",
    "X5_train, X5_validate, y5_train, y5_validate = train_test_split(X5_train_validate, y5_train_validate, test_size = .30, random_state = 123)\n",
    "\n",
    "print(\"train: \", X5_train.shape, \", validate: \", X5_validate.shape, \", test: \", X5_test.shape)\n",
    "print(\"train: \", y5_train.shape, \", validate: \", y5_validate.shape, \", test: \", y5_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Basic Model\n",
    "# Create Logistic Regression Object\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "logit5 = LogisticRegression(C=1, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit Model to the Data\n",
    "logit5.fit(X5_train, y5_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-1.13193462 -1.13193462  1.44382804]]\n",
      "Intercept: \n",
      " [0.47332721]\n"
     ]
    }
   ],
   "source": [
    "#Print the coefficients and intercept of the model\n",
    "print('Coefficient: \\n', logit5.coef_)\n",
    "print('Intercept: \\n', logit5.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate whether or not a passenger would survive, using the training data\n",
    "y5_pred = logit5.predict(X5_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Model 1\n",
      " [[260  53]\n",
      " [ 62 122]]\n"
     ]
    }
   ],
   "source": [
    "#Accuracy of Logistic Regression classifier on training set: 0.37\n",
    "#Create a confusion matrix\n",
    "print(\"Confusion Matrix for Model 1\\n\",confusion_matrix(y5_train, y5_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.77\n"
     ]
    }
   ],
   "source": [
    "#Evaluate Model on Train\n",
    "#Compute the accuracy\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'.format(logit5.score(X5_train, y5_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82       313\n",
      "           1       0.70      0.66      0.68       184\n",
      "\n",
      "    accuracy                           0.77       497\n",
      "   macro avg       0.75      0.75      0.75       497\n",
      "weighted avg       0.77      0.77      0.77       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Compute Precision, Recall, F1-score, and Support\n",
    "print(classification_report(y5_train, y5_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of model 5 is 76.86 percent.\n"
     ]
    }
   ],
   "source": [
    "model5_acc = accuracy_score(y5_train, y5_pred)\n",
    "\n",
    "print('The accuracy of model 5 is',round(model5_acc * 100, 2), 'percent.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Accuracy did not change when dropping the age feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For our next model, let's add more features instead of less\n",
    "- age, pclass, gender, fare, alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  (497, 4) , validate:  (214, 4) , test:  (178, 4)\n",
      "train:  (497, 1) , validate:  (214, 1) , test:  (178, 1)\n"
     ]
    }
   ],
   "source": [
    "# choosing features and splitting into train, validate, test\n",
    "# first, let's just test survival by female, child, and first_class\n",
    "X6 = titanic[['age','male','pclass','alone']]\n",
    "y6 = titanic[['survived']]\n",
    "\n",
    "X6_train_validate, X6_test, y6_train_validate, y6_test = train_test_split(X6, y6, test_size = .20, random_state = 123)\n",
    "\n",
    "X6_train, X6_validate, y6_train, y6_validate = train_test_split(X6_train_validate, y6_train_validate, test_size = .30, random_state = 123)\n",
    "\n",
    "print(\"train: \", X6_train.shape, \", validate: \", X6_validate.shape, \", test: \", X6_test.shape)\n",
    "print(\"train: \", y6_train.shape, \", validate: \", y6_validate.shape, \", test: \", y6_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Basic Model\n",
    "# Create Logistic Regression Object\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "logit6 = LogisticRegression(C=1, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit Model to the Data\n",
    "logit6.fit(X6_train, y6_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-0.03074817 -2.13996862 -1.1226487  -0.1564343 ]]\n",
      "Intercept: \n",
      " [4.25691469]\n"
     ]
    }
   ],
   "source": [
    "#Print the coefficients and intercept of the model\n",
    "print('Coefficient: \\n', logit6.coef_)\n",
    "print('Intercept: \\n', logit6.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate whether or not a passenger would survive, using the training data\n",
    "y6_pred = logit6.predict(X6_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Model 1\n",
      " [[266  47]\n",
      " [ 68 116]]\n"
     ]
    }
   ],
   "source": [
    "#Accuracy of Logistic Regression classifier on training set: 0.37\n",
    "#Create a confusion matrix\n",
    "print(\"Confusion Matrix for Model 1\\n\",confusion_matrix(y6_train, y6_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.77\n"
     ]
    }
   ],
   "source": [
    "#Evaluate Model on Train\n",
    "#Compute the accuracy\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'.format(logit6.score(X6_train, y6_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of model 5 is 76.86 percent.\n"
     ]
    }
   ],
   "source": [
    "model6_acc = accuracy_score(y6_train, y6_pred)\n",
    "\n",
    "print('The accuracy of model 5 is',round(model6_acc * 100, 2), 'percent.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's use all the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "      <th>male</th>\n",
       "      <th>is_child</th>\n",
       "      <th>is_first_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.25</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass   sex   age  sibsp  parch  fare embarked  \\\n",
       "0             0         0       3  male  22.0      1      0  7.25        S   \n",
       "\n",
       "   class  embark_town  alone  Q  S  male  is_child  is_first_class  \n",
       "0  Third  Southampton      0  0  1     1     False           False  "
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  (497, 4) , validate:  (214, 4) , test:  (178, 4)\n",
      "train:  (497, 1) , validate:  (214, 1) , test:  (178, 1)\n"
     ]
    }
   ],
   "source": [
    "# choosing features and splitting into train, validate, test\n",
    "# first, let's just test survival by female, child, and first_class\n",
    "X7 = titanic[['pclass','age','sibsp','parch','fare','alone','Q','S','male']]\n",
    "y7 = titanic[['survived']]\n",
    "\n",
    "X7_train_validate, X7_test, y7_train_validate, y7_test = train_test_split(X7, y7, test_size = .20, random_state = 123)\n",
    "\n",
    "X7_train, X7_validate, y7_train, y7_validate = train_test_split(X7_train_validate, y7_train_validate, test_size = .30, random_state = 123)\n",
    "\n",
    "print(\"train: \", X6_train.shape, \", validate: \", X6_validate.shape, \", test: \", X6_test.shape)\n",
    "print(\"train: \", y6_train.shape, \", validate: \", y6_validate.shape, \", test: \", y6_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Basic Model\n",
    "# Create Logistic Regression Object\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "logit7 = LogisticRegression(C=1, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit Model to the Data\n",
    "logit7.fit(X7_train, y7_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-1.02544004e+00 -3.44915225e-02 -4.41728767e-01 -5.52839933e-02\n",
      "   1.43137209e-03 -7.63632322e-01  9.25335626e-02 -3.63917168e-01\n",
      "  -2.13536220e+00]]\n",
      "Intercept: \n",
      " [4.96870432]\n"
     ]
    }
   ],
   "source": [
    "#Print the coefficients and intercept of the model\n",
    "print('Coefficient: \\n', logit7.coef_)\n",
    "print('Intercept: \\n', logit7.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate whether or not a passenger would survive, using the training data\n",
    "y7_pred = logit7.predict(X7_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Model 1\n",
      " [[270  43]\n",
      " [ 63 121]]\n"
     ]
    }
   ],
   "source": [
    "#Accuracy of Logistic Regression classifier on training set: 0.37\n",
    "#Create a confusion matrix\n",
    "print(\"Confusion Matrix for Model 1\\n\",confusion_matrix(y7_train, y7_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.79\n"
     ]
    }
   ],
   "source": [
    "#Evaluate Model on Train\n",
    "#Compute the accuracy\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'.format(logit7.score(X7_train, y7_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of model 7 is 78.67 percent.\n"
     ]
    }
   ],
   "source": [
    "model7_acc = accuracy_score(y7_train, y7_pred)\n",
    "\n",
    "print('The accuracy of model 7 is',round(model7_acc * 100, 2), 'percent.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Use your best 3 models to predict and evaluate on your validate sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy is 62.98 percent.\n",
      "Model 2 accuracy is 72.23 percent.\n",
      "Model 3 accuracy is 77.26 percent.\n",
      "Model 4 accuracy is 76.86 percent.\n",
      "Model 5 accuracy is 76.86 percent.\n",
      "Model 6 accuracy is 76.86 percent.\n",
      "Model 7 accuracy is 78.67 percent.\n"
     ]
    }
   ],
   "source": [
    "print('Baseline accuracy is', round(base_acc * 100,2),'percent.')\n",
    "print('Model 2 accuracy is', round(model2_acc * 100,2),'percent.')\n",
    "print('Model 3 accuracy is', round(model3_acc * 100,2),'percent.')\n",
    "print('Model 4 accuracy is', round(model4_acc * 100,2),'percent.')\n",
    "print('Model 5 accuracy is', round(model5_acc * 100,2),'percent.')\n",
    "print('Model 6 accuracy is', round(model6_acc * 100,2),'percent.')\n",
    "print('Model 7 accuracy is', round(model7_acc * 100,2),'percent.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's evaluate Models 3,4,7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: features = ['pclass','fare','age','male'], c = 1\n",
      "Accuracy: 0.84\n",
      "[[114  16]\n",
      " [ 18  66]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87       130\n",
      "           1       0.80      0.79      0.80        84\n",
      "\n",
      "    accuracy                           0.84       214\n",
      "   macro avg       0.83      0.83      0.83       214\n",
      "weighted avg       0.84      0.84      0.84       214\n",
      "\n",
      "Model 2: features = ['is_child','male','is_first_class'], c = 1\n",
      "Accuracy: 0.84\n",
      "[[116  14]\n",
      " [ 20  64]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87       130\n",
      "           1       0.82      0.76      0.79        84\n",
      "\n",
      "    accuracy                           0.84       214\n",
      "   macro avg       0.84      0.83      0.83       214\n",
      "weighted avg       0.84      0.84      0.84       214\n",
      "\n",
      "Model 3: features = ['pclass','age','sibsp','parch','fare','alone','Q','S','male'], c = 1\n",
      "Accuracy: 0.86\n",
      "[[119  11]\n",
      " [ 20  64]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.88       130\n",
      "           1       0.85      0.76      0.81        84\n",
      "\n",
      "    accuracy                           0.86       214\n",
      "   macro avg       0.85      0.84      0.84       214\n",
      "weighted avg       0.86      0.86      0.85       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred1 = logit3.predict(X3_validate)\n",
    "y_pred2 = logit4.predict(X4_validate)\n",
    "y_pred3 = logit7.predict(X7_validate)\n",
    "\n",
    "# Model 3\n",
    "print(\"Model 1: features = ['pclass','fare','age','male'], c = 1\")\n",
    "\n",
    "print('Accuracy: {:.2f}'.format(logit3.score(X3_validate, y3_validate)))\n",
    "\n",
    "print(confusion_matrix(y3_validate, y_pred1))\n",
    "\n",
    "print(classification_report(y3_validate, y_pred1))\n",
    "\n",
    "#Model 4\n",
    "print(\"Model 2: features = ['is_child','male','is_first_class'], c = 1\")\n",
    "\n",
    "print('Accuracy: {:.2f}'.format(logit4.score(X4_validate, y4_validate)))\n",
    "\n",
    "print(confusion_matrix(y4_validate, y_pred2))\n",
    "\n",
    "print(classification_report(y4_validate, y_pred2))\n",
    "\n",
    "#Model 7\n",
    "print(\"Model 3: features = ['pclass','age','sibsp','parch','fare','alone','Q','S','male'], c = 1\")\n",
    "\n",
    "print('Accuracy: {:.2f}'.format(logit7.score(X7_validate, y7_validate)))\n",
    "\n",
    "print(confusion_matrix(y1_validate, y_pred3))\n",
    "\n",
    "print(classification_report(y1_validate, y_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Choose you best model from the validation performation, and evaluate it on the test dataset. How do the performance metrics compare to validate? to train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: solver = lbfgs, c = 1\n",
      "Accuracy: 0.78\n",
      "[[92 14]\n",
      " [25 47]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83       106\n",
      "           1       0.77      0.65      0.71        72\n",
      "\n",
      "    accuracy                           0.78       178\n",
      "   macro avg       0.78      0.76      0.77       178\n",
      "weighted avg       0.78      0.78      0.78       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Choosing Model 7 as the best predicting survived and not survived\n",
    "y_pred3 = logit7.predict(X7_test)\n",
    "y_pred_proba = logit7.predict_proba(X7_test)\n",
    "\n",
    "print(\"Model 1: solver = lbfgs, c = 1\")\n",
    "\n",
    "print('Accuracy: {:.2f}'.format(logit7.score(X7_test, y7_test)))\n",
    "\n",
    "print(confusion_matrix(y7_test, y_pred3))\n",
    "\n",
    "print(classification_report(y7_test, y_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- performed the best on the validate stage\n",
    "- performed similar accuracy during train and evaluate\n",
    "- overall, it performed better than the baseline (aka best guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bonus1 How do different strategies for handling the missing values in the age column affect model performance?\n",
    "\n",
    "- Bonus2: How do different strategies for encoding sex affect model performance?\n",
    "\n",
    "- Bonus3: scikit-learn's LogisticRegression classifier is actually applying a regularization penalty to the coefficients by default. This penalty causes the magnitude of the coefficients in the resulting model to be smaller than they otherwise would be. This value can be modified with the C hyper parameter. Small values of C correspond to a larger penalty, and large values of C correspond to a smaller penalty.\n",
    "    - Try out the following values for C and note how the coefficients and the model's performance on both the dataset it was trained on and on the validate split are affected.\n",
    "    - C = .01, .1, 1, 10, 100, 1000\n",
    "- Bonus Bonus: how does scaling the data interact with your choice of C?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this exercise, we'll continue working with the titanic dataset and building logistic regression models.\n",
    "- Throughout this exercise, be sure you are training, evaluation, and comparing models on the train and validate datasets. \n",
    "- The test dataset should only be used for your final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree imports complete.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "print('Tree imports complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "      <th>male</th>\n",
       "      <th>is_child</th>\n",
       "      <th>is_first_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.25</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass   sex   age  sibsp  parch  fare embarked  \\\n",
       "0             0         0       3  male  22.0      1      0  7.25        S   \n",
       "\n",
       "   class  embark_town  alone  Q  S  male  is_child  is_first_class  \n",
       "0  Third  Southampton      0  0  1     1     False           False  "
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  (497, 5) , validate:  (214, 5) , test:  (178, 5)\n",
      "train:  (497, 1) , validate:  (214, 1) , test:  (178, 1)\n"
     ]
    }
   ],
   "source": [
    "# prep from curriculum\n",
    "X_tree = titanic[['pclass','male','age','fare','alone']]\n",
    "y_tree = titanic[['survived']]\n",
    "\n",
    "Xtree_train_validate, Xtree_test, ytree_train_validate, ytree_test = train_test_split(X_tree, y_tree, test_size = .20, random_state = 123)\n",
    "\n",
    "Xtree_train, Xtree_validate, ytree_train, ytree_validate = train_test_split(Xtree_train_validate, ytree_train_validate, test_size = .30, random_state = 123)\n",
    "\n",
    "print(\"train: \", Xtree_train.shape, \", validate: \", Xtree_validate.shape, \", test: \", Xtree_test.shape)\n",
    "print(\"train: \", ytree_train.shape, \", validate: \", ytree_validate.shape, \", test: \", ytree_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=123, splitter='best')"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(Xtree_train, ytree_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytree_pred = clf.predict(Xtree_train)\n",
    "ytree_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.1       , 0.9       ],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [1.        , 0.        ],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.1       , 0.9       ],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.1       , 0.9       ],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.1       , 0.9       ],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [1.        , 0.        ],\n",
       "       [0.1       , 0.9       ],\n",
       "       [0.1       , 0.9       ],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.1       , 0.9       ],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.1       , 0.9       ],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [1.        , 0.        ],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.1       , 0.9       ],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.1       , 0.9       ],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122]])"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytree_pred_proba = clf.predict_proba(Xtree_train)\n",
    "ytree_pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 0.83\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "     .format(clf.score(Xtree_train, ytree_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Decision Tree Classifier:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[298,  15],\n",
       "       [ 71, 113]])"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Confusion Matrix of Decision Tree Classifier:')\n",
    "confusion_matrix(ytree_train, ytree_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.87       313\n",
      "           1       0.88      0.61      0.72       184\n",
      "\n",
      "    accuracy                           0.83       497\n",
      "   macro avg       0.85      0.78      0.80       497\n",
      "weighted avg       0.84      0.83      0.82       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytree_train, ytree_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "497"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytree_pred\n",
    "ytree_train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP = confusion_matrix(ytree_train, ytree_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: \n",
      "__________0.83\n",
      "true positive rate: \n",
      "____________________0.61\n",
      "false positive rate: \n",
      "____________________0.05\n",
      "true negative rate: \n",
      "____________________0.95\n",
      "false negative rate: \n",
      "____________________0.19\n",
      "precision: \n",
      "__________0.88\n",
      "recall: \n",
      "_______0.61\n",
      "f1-score: \n",
      "_________0.72\n",
      "support: \n",
      "________[313 184]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Accuracy is the rate of correct predictions\n",
    "accuracy1= accuracy_score(ytree_pred, ytree_train)\n",
    "acc1= ((TP + TN) / (TP + TN + FP + FN))\n",
    "\n",
    "# Recall is the true positive rate\n",
    "recall1=recall_score(ytree_train, ytree_pred)\n",
    "rec1= (TP / (TP + FN))\n",
    "\n",
    "# False positive rate\n",
    "fp_rate1= (FP / (FP + TN))\n",
    "\n",
    "# Specificity is the true negative rate\n",
    "spec1= (TN /(TN + FP))\n",
    "\n",
    "# False negative rate\n",
    "fn_rate1= (FN / (FN + TN))\n",
    "\n",
    "# Precision is the psitive pedictive value\n",
    "prec1= (TP / (TP + FP))\n",
    "\n",
    "# f1-score\n",
    "f_score1= f1_score(ytree_train, ytree_pred)\n",
    "#F1 = 2 * (prec * recall) / (prec + recall)\n",
    "\n",
    "# Support is the number of occurrences of each class in y_true\n",
    "support1= precision_recall_fscore_support(ytree_train, ytree_pred)[-1]\n",
    "\n",
    "print(f'''\n",
    "Accuracy: \\n__________{round(accuracy1,2)}\n",
    "true positive rate: \\n____________________{round(recall1,2)}\n",
    "false positive rate: \\n____________________{round(fp_rate1,2)}\n",
    "true negative rate: \\n____________________{round(spec1,2)}\n",
    "false negative rate: \\n____________________{round(fn_rate1,2)}\n",
    "precision: \\n__________{round(prec1,2)}\n",
    "recall: \\n_______{round(recall1,2)}\n",
    "f1-score: \\n_________{round(f_score1,2)}\n",
    "support: \\n________{support1}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run through steps 2-4 using a different max_depth value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This time, we will change the depth to 4 instead of 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = DecisionTreeClassifier(max_depth=4, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=4, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=123, splitter='best')"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.fit(Xtree_train, ytree_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytree_pred = clf2.predict(Xtree_train)\n",
    "ytree_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.1       , 0.9       ],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [1.        , 0.        ],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.1       , 0.9       ],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.1       , 0.9       ],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.1       , 0.9       ],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [1.        , 0.        ],\n",
       "       [0.1       , 0.9       ],\n",
       "       [0.1       , 0.9       ],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.1       , 0.9       ],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.1       , 0.9       ],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [1.        , 0.        ],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.1       , 0.9       ],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.1       , 0.9       ],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.33333333, 0.66666667],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.01785714, 0.98214286],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.87804878, 0.12195122],\n",
       "       [0.63492063, 0.36507937],\n",
       "       [0.87804878, 0.12195122]])"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytree_pred_proba = clf.predict_proba(Xtree_train)\n",
    "ytree_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set with Depth of 4: 0.84\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Decision Tree classifier on training set with Depth of 4: {:.2f}'\n",
    "     .format(clf2.score(Xtree_train, ytree_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Decision Tree Classifier Model 2:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[298,  15],\n",
       "       [ 64, 120]])"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Confusion Matrix of Decision Tree Classifier Model 2:')\n",
    "confusion_matrix(ytree_train, ytree_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       313\n",
      "           1       0.89      0.65      0.75       184\n",
      "\n",
      "    accuracy                           0.84       497\n",
      "   macro avg       0.86      0.80      0.82       497\n",
      "weighted avg       0.85      0.84      0.83       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytree_train, ytree_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP = confusion_matrix(ytree_train, ytree_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: \n",
      "__________0.84\n",
      "true positive rate: \n",
      "____________________0.65\n",
      "false positive rate: \n",
      "____________________0.05\n",
      "true negative rate: \n",
      "____________________0.95\n",
      "false negative rate: \n",
      "____________________0.18\n",
      "precision: \n",
      "__________0.89\n",
      "recall: \n",
      "_______0.65\n",
      "f1-score: \n",
      "_________0.75\n",
      "support: \n",
      "________[313 184]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Accuracy is the rate of correct predictions\n",
    "accuracy2 = accuracy_score(ytree_pred, ytree_train)\n",
    "acc2 = ((TP + TN) / (TP + TN + FP + FN))\n",
    "\n",
    "# Recall is the true positive rate\n",
    "recall2= recall_score(ytree_train, ytree_pred)\n",
    "rec2 = (TP / (TP + FN))\n",
    "\n",
    "# False positive rate\n",
    "fp_rate2 = (FP / (FP + TN))\n",
    "\n",
    "# Specificity is the true negative rate\n",
    "spec2 = (TN /(TN + FP))\n",
    "\n",
    "# False negative rate\n",
    "fn_rate2 = (FN / (FN + TN))\n",
    "\n",
    "# Precision is the psitive pedictive value\n",
    "prec2 = (TP / (TP + FP))\n",
    "\n",
    "# f1-score\n",
    "f_score2 = f1_score(ytree_train, ytree_pred)\n",
    "F1 = 2 * (prec * recall) / (prec + recall)\n",
    "\n",
    "# Support is the number of occurrences of each class in y_true\n",
    "support2 = precision_recall_fscore_support(ytree_train, ytree_pred)[-1]\n",
    "\n",
    "print(f'''\n",
    "Accuracy: \\n__________{round(accuracy2,2)}\n",
    "true positive rate: \\n____________________{round(recall2,2)}\n",
    "false positive rate: \\n____________________{round(fp_rate2,2)}\n",
    "true negative rate: \\n____________________{round(spec2,2)}\n",
    "false negative rate: \\n____________________{round(fn_rate2,2)}\n",
    "precision: \\n__________{round(prec2,2)}\n",
    "recall: \\n_______{round(recall2,2)}\n",
    "f1-score: \\n_________{round(f_score2,2)}\n",
    "support: \\n________{support2}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This time we will change the depth to 5 instead of 3 and 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3 = DecisionTreeClassifier(max_depth=5, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=5, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=123, splitter='best')"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3.fit(Xtree_train, ytree_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytree_pred = clf3.predict(Xtree_train)\n",
    "ytree_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set with Depth of 4: 0.84\n",
      "\n",
      "Confusion Matrix of Decision Tree Classifier Model 2:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89       313\n",
      "           1       0.93      0.63      0.75       184\n",
      "\n",
      "    accuracy                           0.85       497\n",
      "   macro avg       0.87      0.80      0.82       497\n",
      "weighted avg       0.86      0.85      0.84       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ytree_pred_proba = clf.predict_proba(Xtree_train)\n",
    "\n",
    "print('Accuracy of Decision Tree classifier on training set with Depth of 4: {:.2f}'\n",
    "     .format(clf2.score(Xtree_train, ytree_train)))\n",
    "\n",
    "print('\\nConfusion Matrix of Decision Tree Classifier Model 2:')\n",
    "confusion_matrix(ytree_train, ytree_pred)\n",
    "\n",
    "print('\\n',classification_report(ytree_train, ytree_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP = confusion_matrix(ytree_train, ytree_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: \n",
      "__________0.85\n",
      "true positive rate: \n",
      "____________________0.63\n",
      "false positive rate: \n",
      "____________________0.03\n",
      "true negative rate: \n",
      "____________________0.97\n",
      "false negative rate: \n",
      "____________________0.18\n",
      "precision: \n",
      "__________0.93\n",
      "recall: \n",
      "_______0.63\n",
      "f1-score: \n",
      "_________0.75\n",
      "support: \n",
      "________[313 184]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Accuracy is the rate of correct predictions\n",
    "accuracy3 = accuracy_score(ytree_pred, ytree_train)\n",
    "acc3 = ((TP + TN) / (TP + TN + FP + FN))\n",
    "\n",
    "# Recall is the true positive rate\n",
    "recall3= recall_score(ytree_train, ytree_pred)\n",
    "rec3 = (TP / (TP + FN))\n",
    "\n",
    "# False positive rate\n",
    "fp_rate3 = (FP / (FP + TN))\n",
    "\n",
    "# Specificity is the true negative rate\n",
    "spec3 = (TN /(TN + FP))\n",
    "\n",
    "# False negative rate\n",
    "fn_rate3 = (FN / (FN + TN))\n",
    "\n",
    "# Precision is the psitive pedictive value\n",
    "prec3 = (TP / (TP + FP))\n",
    "\n",
    "# f1-score\n",
    "f_score3 = f1_score(ytree_train, ytree_pred)\n",
    "F1 = 2 * (prec * recall) / (prec + recall)\n",
    "\n",
    "# Support is the number of occurrences of each class in y_true\n",
    "support3 = precision_recall_fscore_support(ytree_train, ytree_pred)[-1]\n",
    "\n",
    "print(f'''\n",
    "Accuracy: \\n__________{round(accuracy3,2)}\n",
    "true positive rate: \\n____________________{round(recall3,2)}\n",
    "false positive rate: \\n____________________{round(fp_rate3,2)}\n",
    "true negative rate: \\n____________________{round(spec3,2)}\n",
    "false negative rate: \\n____________________{round(fn_rate3,2)}\n",
    "precision: \\n__________{round(prec3,2)}\n",
    "recall: \\n_______{round(recall3,2)}\n",
    "f1-score: \\n_________{round(f_score3,2)}\n",
    "support: \\n________{support3}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Which performs better on your in-sample data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tested\n",
    "    - Model 1 with Depth = 3\n",
    "    - Model 2 with Depth = 4\n",
    "    - Model 3 with Depth = 5\n",
    "    \n",
    "- While Model 3 seems the best, we must be careful of this being on overfit of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: \n",
      "0.83\n",
      "true positive rate: \n",
      "0.61\n",
      "false positive rate: \n",
      "0.05\n",
      "true negative rate: \n",
      "0.95\n",
      "false negative rate: \n",
      "0.19\n",
      "precision: \n",
      "0.88\n",
      "recall: \n",
      "0.61\n",
      "f1-score: \n",
      "0.72\n",
      "support: \n",
      "[313 184]\n",
      "\n",
      "\n",
      "Accuracy: \n",
      "0.84\n",
      "true positive rate: \n",
      "0.65\n",
      "false positive rate: \n",
      "0.05\n",
      "true negative rate: \n",
      "0.95\n",
      "false negative rate: \n",
      "0.18\n",
      "precision: \n",
      "0.89\n",
      "recall: \n",
      "0.65\n",
      "f1-score: \n",
      "0.75\n",
      "support: \n",
      "[313 184]\n",
      "\n",
      "\n",
      "Accuracy: \n",
      "0.85\n",
      "true positive rate: \n",
      "0.63\n",
      "false positive rate: \n",
      "0.03\n",
      "true negative rate: \n",
      "0.97\n",
      "false negative rate: \n",
      "0.18\n",
      "precision: \n",
      "0.93\n",
      "recall: \n",
      "0.63\n",
      "f1-score: \n",
      "0.75\n",
      "support: \n",
      "[313 184]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model 1\n",
    "print(f'''\n",
    "Accuracy: \\n{round(accuracy1,2)}\n",
    "true positive rate: \\n{round(recall1,2)}\n",
    "false positive rate: \\n{round(fp_rate1,2)}\n",
    "true negative rate: \\n{round(spec1,2)}\n",
    "false negative rate: \\n{round(fn_rate1,2)}\n",
    "precision: \\n{round(prec1,2)}\n",
    "recall: \\n{round(recall1,2)}\n",
    "f1-score: \\n{round(f_score1,2)}\n",
    "support: \\n{support1}\n",
    "''')\n",
    "\n",
    "# model 2\n",
    "print(f'''\n",
    "Accuracy: \\n{round(accuracy2,2)}\n",
    "true positive rate: \\n{round(recall2,2)}\n",
    "false positive rate: \\n{round(fp_rate2,2)}\n",
    "true negative rate: \\n{round(spec2,2)}\n",
    "false negative rate: \\n{round(fn_rate2,2)}\n",
    "precision: \\n{round(prec2,2)}\n",
    "recall: \\n{round(recall2,2)}\n",
    "f1-score: \\n{round(f_score2,2)}\n",
    "support: \\n{support2}\n",
    "''')\n",
    "\n",
    "#model 2\n",
    "print(f'''\n",
    "Accuracy: \\n{round(accuracy3,2)}\n",
    "true positive rate: \\n{round(recall3,2)}\n",
    "false positive rate: \\n{round(fp_rate3,2)}\n",
    "true negative rate: \\n{round(spec3,2)}\n",
    "false negative rate: \\n{round(fn_rate3,2)}\n",
    "precision: \\n{round(prec3,2)}\n",
    "recall: \\n{round(recall3,2)}\n",
    "f1-score: \\n{round(f_score3,2)}\n",
    "support: \\n{support3}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Visualize Model 1 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "\n",
    "from graphviz import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'titanic_decision_tree.pdf'"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## need to install graphviz to anaconda\n",
    "## example: \n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=123)\n",
    "clf = clf.fit(X_tree, y_tree)\n",
    "\n",
    "import graphviz\n",
    "\n",
    "from graphviz import Graph\n",
    "\n",
    "dot_data = export_graphviz(clf, out_file=None) \n",
    "graph = graphviz.Source(dot_data) \n",
    "\n",
    "graph.render('titanic_decision_tree', view=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## need to install graphviz to anaconda\n",
    "## example: \n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=4, random_state=123)\n",
    "clf = clf.fit(X_tree, y_tree)\n",
    "\n",
    "import graphviz\n",
    "\n",
    "from graphviz import Graph\n",
    "\n",
    "dot_data = export_graphviz(clf, out_file=None) \n",
    "graph = graphviz.Source(dot_data) \n",
    "\n",
    "graph.render('titanic_decision_tree', view=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'titanic_decision_tree.pdf'"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## need to install graphviz to anaconda\n",
    "## example: \n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=5, random_state=123)\n",
    "clf = clf.fit(X_tree, y_tree)\n",
    "\n",
    "import graphviz\n",
    "\n",
    "from graphviz import Graph\n",
    "\n",
    "dot_data = export_graphviz(clf, out_file=None, \n",
    "                           feature_names = X_tree.columns, \n",
    "                           class_names = {0:'not survived',1:'survived}'},\n",
    "                          rounded=True,\n",
    "                          filled=True) \n",
    "graph = graphviz.Source(dot_data) \n",
    "\n",
    "graph.render('titanic_decision_tree', view=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Models on Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "passenger_id        int64\n",
       "survived            int64\n",
       "pclass              int64\n",
       "sex                object\n",
       "age               float64\n",
       "sibsp               int64\n",
       "parch               int64\n",
       "fare              float64\n",
       "embarked           object\n",
       "class              object\n",
       "embark_town        object\n",
       "alone               int64\n",
       "Q                   uint8\n",
       "S                   uint8\n",
       "male                uint8\n",
       "is_child             bool\n",
       "is_first_class       bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  (497, 5) , validate:  (214, 5) , test:  (178, 5)\n",
      "train:  (497, 1) , validate:  (214, 1) , test:  (178, 1)\n"
     ]
    }
   ],
   "source": [
    "X_rf = titanic[['pclass','male','age','fare','alone']]\n",
    "y_rf = titanic[['survived']]\n",
    "\n",
    "Xrf_train_validate, Xrf_test, yrf_train_validate, yrf_test = train_test_split(X_rf, y_rf, test_size = .20, random_state = 123)\n",
    "\n",
    "Xrf_train, Xrf_validate, yrf_train, yrf_validate = train_test_split(Xrf_train_validate, yrf_train_validate, test_size = .30, random_state = 123)\n",
    "\n",
    "print(\"train: \", Xrf_train.shape, \", validate: \", Xrf_validate.shape, \", test: \", Xrf_test.shape)\n",
    "print(\"train: \", yrf_train.shape, \", validate: \", yrf_validate.shape, \", test: \", yrf_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=123, min_samples_leaf = 1, max_depth = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=20, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=123,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(Xrf_train, yrf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10188932 0.21528082 0.29625531 0.35705755 0.029517  ]\n"
     ]
    }
   ],
   "source": [
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(Xrf_train)\n",
    "y_pred_proba = rf.predict_proba(Xrf_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier Model 1 on training set: 0.98\n",
      "\n",
      "Confusion Matrix of RF Model 1:\n",
      "[[311   2]\n",
      " [  6 178]]\n",
      "\n",
      "Classification Report of RF Model 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       313\n",
      "           1       0.99      0.97      0.98       184\n",
      "\n",
      "    accuracy                           0.98       497\n",
      "   macro avg       0.98      0.98      0.98       497\n",
      "weighted avg       0.98      0.98      0.98       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of random forest classifier Model 1 on training set: {:.2f}'\n",
    "     .format(rf.score(Xrf_train, yrf_train)))\n",
    "\n",
    "print('\\nConfusion Matrix of RF Model 1:')\n",
    "print(confusion_matrix(yrf_train, y_pred))\n",
    "\n",
    "print('\\nClassification Report of RF Model 1:')\n",
    "print(classification_report(yrf_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP = confusion_matrix(yrf_train, y_pred).ravel()\n",
    "\n",
    "# Accuracy is the rate of correct predictions\n",
    "accuracy_rf = accuracy_score(y_pred, yrf_train)\n",
    "acc_rf = ((TP + TN) / (TP + TN + FP + FN))\n",
    "\n",
    "# Recall is the true positive rate\n",
    "recall_rf = recall_score(yrf_train, y_pred)\n",
    "rec_rf = (TP / (TP + FN))\n",
    "\n",
    "# False positive rate\n",
    "fp_rate_rf = (FP / (FP + TN))\n",
    "\n",
    "# Specificity is the true negative rate\n",
    "spec_rf = (TN /(TN + FP))\n",
    "\n",
    "# False negative rate\n",
    "fn_rate_rf = (FN / (FN + TN))\n",
    "\n",
    "# Precision is the psitive pedictive value\n",
    "prec_rf = (TP / (TP + FP))\n",
    "\n",
    "# f1-score\n",
    "f_score_rf = f1_score(yrf_train, y_pred)\n",
    "F1_rf = 2 * (prec * recall) / (prec + recall)\n",
    "\n",
    "# Support is the number of occurrences of each class in y_true\n",
    "support_rf = precision_recall_fscore_support(ytree_train, ytree_pred)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RF Model 1 stats\n",
      "Accuracy: \n",
      "0.98\n",
      "true positive rate: \n",
      "0.97\n",
      "false positive rate: \n",
      "0.01\n",
      "true negative rate: \n",
      "0.99\n",
      "false negative rate: \n",
      "0.02\n",
      "precision: \n",
      "0.99\n",
      "recall: \n",
      "0.97\n",
      "f1-score: \n",
      "0.98\n",
      "support: \n",
      "[313 184]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model 1\n",
    "print(f'''\n",
    "RF Model 1 stats\n",
    "Accuracy: \\n{round(accuracy_rf,2)}\n",
    "true positive rate: \\n{round(recall_rf,2)}\n",
    "false positive rate: \\n{round(fp_rate_rf,2)}\n",
    "true negative rate: \\n{round(spec_rf,2)}\n",
    "false negative rate: \\n{round(fn_rate_rf,2)}\n",
    "precision: \\n{round(prec_rf,2)}\n",
    "recall: \\n{round(recall_rf,2)}\n",
    "f1-score: \\n{round(f_score_rf,2)}\n",
    "support: \\n{support_rf}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run through steps increasing your min_samples_leaf to 5 and decreasing your max_depth to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier model 2 on training set: 0.82\n",
      "\n",
      "Confusion Matrix of RF Model 2:\n",
      "[[299  14]\n",
      " [ 77 107]]\n",
      "\n",
      "Classification Report of RF Model 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.96      0.87       313\n",
      "           1       0.88      0.58      0.70       184\n",
      "\n",
      "    accuracy                           0.82       497\n",
      "   macro avg       0.84      0.77      0.78       497\n",
      "weighted avg       0.83      0.82      0.81       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf2 = RandomForestClassifier(random_state=123, min_samples_leaf = 5, max_depth = 3)\n",
    "\n",
    "rf2.fit(Xrf_train, yrf_train)\n",
    "\n",
    "y_pred2 = rf2.predict(Xrf_train)\n",
    "\n",
    "y_pred_proba2 = rf2.predict_proba(Xrf_train)\n",
    "\n",
    "print('Accuracy of random forest classifier model 2 on training set: {:.2f}'\n",
    "     .format(rf2.score(Xrf_train, yrf_train)))\n",
    "\n",
    "print('\\nConfusion Matrix of RF Model 2:')\n",
    "print(confusion_matrix(yrf_train, y_pred2))\n",
    "\n",
    "print('\\nClassification Report of RF Model 2:')\n",
    "print(classification_report(yrf_train, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model 1 performs better\n",
    "    - higher accuracy, precision, recall\n",
    "- Model 1 may be overfitted to the data\n",
    "    - performs better in-sample because it is too specific for the data it is training for\n",
    "- Max depth means more the splits it has and captures more information about the data\n",
    "    - too much causes overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- min_samples_leaf is the minimum number of samples required to be at a leaf node\n",
    "- min_samples_split represents the minimum number of samples required to split an internal node.\n",
    "- n_estimators represents the number of trees in the forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier model 3 on training set: 0.84\n",
      "\n",
      "Confusion Matrix of RF Model 3:\n",
      "[[299  14]\n",
      " [ 64 120]]\n",
      "\n",
      "Classification Report of RF Model 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.88       313\n",
      "           1       0.90      0.65      0.75       184\n",
      "\n",
      "    accuracy                           0.84       497\n",
      "   macro avg       0.86      0.80      0.82       497\n",
      "weighted avg       0.85      0.84      0.84       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf3 = RandomForestClassifier(random_state=123, min_samples_split = 5, min_samples_leaf = 5, max_depth = 5)\n",
    "\n",
    "rf3.fit(Xrf_train, yrf_train)\n",
    "\n",
    "y_pred3 = rf3.predict(Xrf_train)\n",
    "\n",
    "y_pred_proba3 = rf3.predict_proba(Xrf_train)\n",
    "\n",
    "print('Accuracy of random forest classifier model 3 on training set: {:.2f}'\n",
    "     .format(rf3.score(Xrf_train, yrf_train)))\n",
    "\n",
    "print('\\nConfusion Matrix of RF Model 3:')\n",
    "print(confusion_matrix(yrf_train, y_pred3))\n",
    "\n",
    "print('\\nClassification Report of RF Model 3:')\n",
    "print(classification_report(yrf_train, y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier model 4 on training set: 0.80\n",
      "\n",
      "Confusion Matrix of RF Model 4:\n",
      "[[303  10]\n",
      " [ 88  96]]\n",
      "\n",
      "Classification Report of RF Model 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.97      0.86       313\n",
      "           1       0.91      0.52      0.66       184\n",
      "\n",
      "    accuracy                           0.80       497\n",
      "   macro avg       0.84      0.74      0.76       497\n",
      "weighted avg       0.82      0.80      0.79       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf4 = RandomForestClassifier(random_state=123, min_samples_leaf = 5, min_samples_split = 10, max_depth = 3, n_estimators=10)\n",
    "\n",
    "rf4.fit(Xrf_train, yrf_train)\n",
    "\n",
    "y_pred4 = rf4.predict(Xrf_train)\n",
    "\n",
    "y_pred_proba4 = rf4.predict_proba(Xrf_train)\n",
    "\n",
    "print('Accuracy of random forest classifier model 4 on training set: {:.2f}'\n",
    "     .format(rf4.score(Xrf_train, yrf_train)))\n",
    "\n",
    "print('\\nConfusion Matrix of RF Model 4:')\n",
    "print(confusion_matrix(yrf_train, y_pred4))\n",
    "\n",
    "print('\\nClassification Report of RF Model 4:')\n",
    "print(classification_report(yrf_train, y_pred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier model 5 on training set: 0.87\n",
      "\n",
      "Confusion Matrix of RF Model 5:\n",
      "[[296  17]\n",
      " [ 49 135]]\n",
      "\n",
      "Classification Report of RF Model 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90       313\n",
      "           1       0.89      0.73      0.80       184\n",
      "\n",
      "    accuracy                           0.87       497\n",
      "   macro avg       0.87      0.84      0.85       497\n",
      "weighted avg       0.87      0.87      0.86       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf5 = RandomForestClassifier(random_state=123, min_samples_leaf = 5, min_samples_split = 10, max_depth = 10, n_estimators=200)\n",
    "\n",
    "rf5.fit(Xrf_train, yrf_train)\n",
    "\n",
    "y_pred5 = rf5.predict(Xrf_train)\n",
    "\n",
    "y_pred_proba5 = rf5.predict_proba(Xrf_train)\n",
    "\n",
    "print('Accuracy of random forest classifier model 5 on training set: {:.2f}'\n",
    "     .format(rf5.score(Xrf_train, yrf_train)))\n",
    "\n",
    "print('\\nConfusion Matrix of RF Model 5:')\n",
    "print(confusion_matrix(yrf_train, y_pred5))\n",
    "\n",
    "print('\\nClassification Report of RF Model 5:')\n",
    "print(classification_report(yrf_train, y_pred5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. After making a few models, which one has the best performance (or closest metrics) on both train and validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1:\n",
      "min_samples_leaf = 1, max_depth = 20\n",
      "Accuracy on Train: 0.9839034205231388\n",
      "\n",
      "Model 2:\n",
      "min_samples_leaf = 5, max_depth = 3\n",
      "Accuracy on Train: 0.8169014084507042\n",
      "\n",
      "Model 3:\n",
      "min_samples_split = 5, min_samples_leaf = 5, max_depth = 5\n",
      "Accuracy on Train: 0.8430583501006036\n",
      "\n",
      "Model 4:\n",
      "min_samples_leaf = 5, min_samples_split = 10, max_depth = 3, n_estimators=10\n",
      "Accuracy on Train: 0.8028169014084507\n",
      "\n",
      "Model 5:\n",
      "min_samples_leaf = 5, min_samples_split = 10, max_depth = 10, n_estimators=200\n",
      "Accuracy on Train: 0.8672032193158954\n"
     ]
    }
   ],
   "source": [
    "print('Model 1:')\n",
    "print('min_samples_leaf = 1, max_depth = 20')\n",
    "print('Accuracy on Train:', rf.score(Xrf_train, yrf_train))\n",
    "\n",
    "print('\\nModel 2:')\n",
    "print('min_samples_leaf = 5, max_depth = 3')\n",
    "print('Accuracy on Train:', rf2.score(Xrf_train, yrf_train))\n",
    "\n",
    "print('\\nModel 3:')\n",
    "print('min_samples_split = 5, min_samples_leaf = 5, max_depth = 5')\n",
    "print('Accuracy on Train:', rf3.score(Xrf_train, yrf_train))\n",
    "\n",
    "print('\\nModel 4:')\n",
    "print('min_samples_leaf = 5, min_samples_split = 10, max_depth = 3, n_estimators=10')\n",
    "print('Accuracy on Train:', rf4.score(Xrf_train, yrf_train))\n",
    "\n",
    "print('\\nModel 5:')\n",
    "print('min_samples_leaf = 5, min_samples_split = 10, max_depth = 10, n_estimators=200')\n",
    "print('Accuracy on Train:', rf5.score(Xrf_train, yrf_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier Model 1 on test set: 0.82\n",
      "Accuracy of random forest classifier Model 5 on test set: 0.85\n",
      "Accuracy of random forest classifier Model 4 on test set: 0.81\n"
     ]
    }
   ],
   "source": [
    "# testing top 2 model and lowest model on validate data\n",
    "\n",
    "#model 1\n",
    "print('Accuracy of random forest classifier Model 1 on test set: {:.2f}'\n",
    "     .format(rf.score(Xrf_validate, yrf_validate)))\n",
    "\n",
    "#model 5\n",
    "print('Accuracy of random forest classifier Model 5 on test set: {:.2f}'\n",
    "     .format(rf5.score(Xrf_validate, yrf_validate)))\n",
    "\n",
    "#model 4\n",
    "print('Accuracy of random forest classifier Model 4 on test set: {:.2f}'\n",
    "     .format(rf4.score(Xrf_validate, yrf_validate)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model 5 was the most consistent from train to validate\n",
    "- Model 1 was overfitted to the train data\n",
    "- Model 4 was consistent from train to validate, but overal had a lower score than Model 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbors Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Fit a K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  (497, 5) , validate:  (214, 5) , test:  (178, 5)\n",
      "train:  (497, 1) , validate:  (214, 1) , test:  (178, 1)\n"
     ]
    }
   ],
   "source": [
    "X_Knn = titanic[['pclass','male','age','fare','alone']]\n",
    "y_Knn = titanic[['survived']]\n",
    "\n",
    "XKnn_train_validate, XKnn_test, yKnn_train_validate, yKnn_test = train_test_split(X_Knn, y_Knn, test_size = .20, random_state = 123)\n",
    "\n",
    "XKnn_train, XKnn_validate, yKnn_train, yKnn_validate = train_test_split(XKnn_train_validate, yKnn_train_validate, test_size = .30, random_state = 123)\n",
    "\n",
    "print(\"train: \", XKnn_train.shape, \", validate: \", XKnn_validate.shape, \", test: \", XKnn_test.shape)\n",
    "print(\"train: \", yKnn_train.shape, \", validate: \", yKnn_validate.shape, \", test: \", yKnn_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn1 = KNeighborsClassifier()\n",
    "knn1.fit(XKnn_train, yKnn_train)\n",
    "y_pred1 = knn1.predict(XKnn_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier Model 1 on training set: 0.78\n",
      "\n",
      "Confusion Matrix of KNN Model 1\n",
      "[[265  48]\n",
      " [ 60 124]]\n",
      "\n",
      "Classification report of KNN Model 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.83       313\n",
      "           1       0.72      0.67      0.70       184\n",
      "\n",
      "    accuracy                           0.78       497\n",
      "   macro avg       0.77      0.76      0.76       497\n",
      "weighted avg       0.78      0.78      0.78       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of KNN classifier Model 1 on training set: {:.2f}'\n",
    "     .format(knn1.score(XKnn_train, yKnn_train)))\n",
    "\n",
    "print('\\nConfusion Matrix of KNN Model 1')\n",
    "print(confusion_matrix(yKnn_train, y_pred1))\n",
    "\n",
    "print('\\nClassification report of KNN Model 1')\n",
    "print(classification_report(yKnn_train, y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KNN Model 1 stats\n",
      "Accuracy: \n",
      "0.78\n",
      "true positive rate: \n",
      "0.67\n",
      "false positive rate: \n",
      "0.15\n",
      "true negative rate: \n",
      "0.85\n",
      "false negative rate: \n",
      "0.18\n",
      "precision: \n",
      "0.72\n",
      "recall: \n",
      "0.67\n",
      "f1-score: \n",
      "0.7\n",
      "support: \n",
      "[313 184]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TN, FP, FN, TP = confusion_matrix(yKnn_train, y_pred1).ravel()\n",
    "\n",
    "# Accuracy is the rate of correct predictions\n",
    "accuracy_Knn = accuracy_score(yKnn_train, y_pred1)\n",
    "acc_Knn = ((TP + TN) / (TP + TN + FP + FN))\n",
    "\n",
    "# Recall is the true positive rate\n",
    "recall_Knn = recall_score(yKnn_train, y_pred1)\n",
    "rec_Knn = (TP / (TP + FN))\n",
    "\n",
    "# False positive rate\n",
    "fp_rate_Knn = (FP / (FP + TN))\n",
    "\n",
    "# Specificity is the true negative rate\n",
    "spec_Knn = (TN /(TN + FP))\n",
    "\n",
    "# False negative rate\n",
    "fn_rate_Knn = (FN / (FN + TN))\n",
    "\n",
    "# Precision is the psitive pedictive value\n",
    "prec_Knn = (TP / (TP + FP))\n",
    "\n",
    "# f1-score\n",
    "f_score_Knn = f1_score(yKnn_train, y_pred1)\n",
    "F1_Knn = 2 * (prec * recall) / (prec + recall)\n",
    "\n",
    "# Support is the number of occurrences of each class in y_true\n",
    "support_Knn = precision_recall_fscore_support(yKnn_train, y_pred1)[-1]\n",
    "\n",
    "# model 1\n",
    "print(f'''\n",
    "KNN Model 1 stats\n",
    "Accuracy: \\n{round(accuracy_Knn,2)}\n",
    "true positive rate: \\n{round(recall_Knn,2)}\n",
    "false positive rate: \\n{round(fp_rate_Knn,2)}\n",
    "true negative rate: \\n{round(spec_Knn,2)}\n",
    "false negative rate: \\n{round(fn_rate_Knn,2)}\n",
    "precision: \\n{round(prec_Knn,2)}\n",
    "recall: \\n{round(recall_Knn,2)}\n",
    "f1-score: \\n{round(f_score_Knn,2)}\n",
    "support: \\n{support_Knn}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run through steps 2-4 setting k to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier Model 2 on training set: 0.74\n",
      "\n",
      "Confusion Matrix of KNN Model 2\n",
      "[[276  37]\n",
      " [ 94  90]]\n",
      "\n",
      "Classification report of KNN Model 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.88      0.81       313\n",
      "           1       0.71      0.49      0.58       184\n",
      "\n",
      "    accuracy                           0.74       497\n",
      "   macro avg       0.73      0.69      0.69       497\n",
      "weighted avg       0.73      0.74      0.72       497\n",
      "\n",
      "\n",
      "KNN Model 2 stats\n",
      "Accuracy: \n",
      "0.74\n",
      "true positive rate: \n",
      "0.49\n",
      "false positive rate: \n",
      "0.12\n",
      "true negative rate: \n",
      "0.88\n",
      "false negative rate: \n",
      "0.25\n",
      "precision: \n",
      "0.71\n",
      "recall: \n",
      "0.49\n",
      "f1-score: \n",
      "0.58\n",
      "support: \n",
      "[313 184]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn2 = KNeighborsClassifier(n_neighbors=10)\n",
    "knn2.fit(XKnn_train, yKnn_train)\n",
    "y_pred2 = knn2.predict(XKnn_train)\n",
    "\n",
    "print('Accuracy of KNN classifier Model 2 on training set: {:.2f}'\n",
    "     .format(knn2.score(XKnn_train, yKnn_train)))\n",
    "\n",
    "print('\\nConfusion Matrix of KNN Model 2')\n",
    "print(confusion_matrix(yKnn_train, y_pred2))\n",
    "\n",
    "print('\\nClassification report of KNN Model 2')\n",
    "print(classification_report(yKnn_train, y_pred2))\n",
    "\n",
    "\n",
    "TN, FP, FN, TP = confusion_matrix(yKnn_train, y_pred2).ravel()\n",
    "\n",
    "# Accuracy is the rate of correct predictions\n",
    "accuracy_Knn = accuracy_score(yKnn_train, y_pred2)\n",
    "acc_Knn = ((TP + TN) / (TP + TN + FP + FN))\n",
    "\n",
    "# Recall is the true positive rate\n",
    "recall_Knn = recall_score(yKnn_train, y_pred2)\n",
    "rec_Knn = (TP / (TP + FN))\n",
    "\n",
    "# False positive rate\n",
    "fp_rate_Knn = (FP / (FP + TN))\n",
    "\n",
    "# Specificity is the true negative rate\n",
    "spec_Knn = (TN /(TN + FP))\n",
    "\n",
    "# False negative rate\n",
    "fn_rate_Knn = (FN / (FN + TN))\n",
    "\n",
    "# Precision is the psitive pedictive value\n",
    "prec_Knn = (TP / (TP + FP))\n",
    "\n",
    "# f1-score\n",
    "f_score_Knn = f1_score(yKnn_train, y_pred2)\n",
    "F1_Knn = 2 * (prec * recall) / (prec + recall)\n",
    "\n",
    "# Support is the number of occurrences of each class in y_true\n",
    "support_Knn = precision_recall_fscore_support(yKnn_train, y_pred1)[-1]\n",
    "\n",
    "# model 1\n",
    "print(f'''\n",
    "KNN Model 2 stats\n",
    "Accuracy: \\n{round(accuracy_Knn,2)}\n",
    "true positive rate: \\n{round(recall_Knn,2)}\n",
    "false positive rate: \\n{round(fp_rate_Knn,2)}\n",
    "true negative rate: \\n{round(spec_Knn,2)}\n",
    "false negative rate: \\n{round(fn_rate_Knn,2)}\n",
    "precision: \\n{round(prec_Knn,2)}\n",
    "recall: \\n{round(recall_Knn,2)}\n",
    "f1-score: \\n{round(f_score_Knn,2)}\n",
    "support: \\n{support_Knn}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run through setps 2-4 setting k to 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier Model 3 on training set: 0.73\n",
      "\n",
      "Confusion Matrix of KNN Model 3\n",
      "[[288  25]\n",
      " [107  77]]\n",
      "\n",
      "Classification report of KNN Model 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.92      0.81       313\n",
      "           1       0.75      0.42      0.54       184\n",
      "\n",
      "    accuracy                           0.73       497\n",
      "   macro avg       0.74      0.67      0.68       497\n",
      "weighted avg       0.74      0.73      0.71       497\n",
      "\n",
      "\n",
      "KNN Model 1 stats\n",
      "Accuracy: \n",
      "0.73\n",
      "true positive rate: \n",
      "0.42\n",
      "false positive rate: \n",
      "0.08\n",
      "true negative rate: \n",
      "0.92\n",
      "false negative rate: \n",
      "0.27\n",
      "precision: \n",
      "0.75\n",
      "recall: \n",
      "0.42\n",
      "f1-score: \n",
      "0.54\n",
      "support: \n",
      "[313 184]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn3 = KNeighborsClassifier(n_neighbors=20)\n",
    "knn3.fit(XKnn_train, yKnn_train)\n",
    "y_pred3 = knn3.predict(XKnn_train)\n",
    "\n",
    "print('Accuracy of KNN classifier Model 3 on training set: {:.2f}'\n",
    "     .format(knn3.score(XKnn_train, yKnn_train)))\n",
    "\n",
    "print('\\nConfusion Matrix of KNN Model 3')\n",
    "print(confusion_matrix(yKnn_train, y_pred3))\n",
    "\n",
    "print('\\nClassification report of KNN Model 3')\n",
    "print(classification_report(yKnn_train, y_pred3))\n",
    "\n",
    "\n",
    "TN, FP, FN, TP = confusion_matrix(yKnn_train, y_pred3).ravel()\n",
    "\n",
    "# Accuracy is the rate of correct predictions\n",
    "accuracy_Knn = accuracy_score(yKnn_train, y_pred3)\n",
    "acc_Knn = ((TP + TN) / (TP + TN + FP + FN))\n",
    "\n",
    "# Recall is the true positive rate\n",
    "recall_Knn = recall_score(yKnn_train, y_pred3)\n",
    "rec_Knn = (TP / (TP + FN))\n",
    "\n",
    "# False positive rate\n",
    "fp_rate_Knn = (FP / (FP + TN))\n",
    "\n",
    "# Specificity is the true negative rate\n",
    "spec_Knn = (TN /(TN + FP))\n",
    "\n",
    "# False negative rate\n",
    "fn_rate_Knn = (FN / (FN + TN))\n",
    "\n",
    "# Precision is the psitive pedictive value\n",
    "prec_Knn = (TP / (TP + FP))\n",
    "\n",
    "# f1-score\n",
    "f_score_Knn = f1_score(yKnn_train, y_pred3)\n",
    "F1_Knn = 2 * (prec * recall) / (prec + recall)\n",
    "\n",
    "# Support is the number of occurrences of each class in y_true\n",
    "support_Knn = precision_recall_fscore_support(yKnn_train, y_pred3)[-1]\n",
    "\n",
    "# model 1\n",
    "print(f'''\n",
    "KNN Model 1 stats\n",
    "Accuracy: \\n{round(accuracy_Knn,2)}\n",
    "true positive rate: \\n{round(recall_Knn,2)}\n",
    "false positive rate: \\n{round(fp_rate_Knn,2)}\n",
    "true negative rate: \\n{round(spec_Knn,2)}\n",
    "false negative rate: \\n{round(fn_rate_Knn,2)}\n",
    "precision: \\n{round(prec_Knn,2)}\n",
    "recall: \\n{round(recall_Knn,2)}\n",
    "f1-score: \\n{round(f_score_Knn,2)}\n",
    "support: \\n{support_Knn}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
